<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <script src="../../js/spark-md5.js"></script>
  </head>
  <body>
    <input type="file" />

    <script>
      const inp = document.querySelector('input')
      inp.onchange = async e => {
        const file = inp.files[0]
        if (!file) {
          return
        }
        /*
         * 获取分片结果
         *
         * 疑问：一个非常大的视频，执行分片函数后得到几十个Blob对象，为啥执行这么快呢？
         * 文件不是很多嘛，怎么瞬间就完成了分片呢 🤔️
         *
         * 消除误解 🔥
         *  无论是File对象还是Blob对象，里面保存的是文件的基本信息，并没有保存文件的数据信息
         *  File: size/type/name
         *  Bolb: size/type
         *
         * 其实对文件进行分片，其实就是一个简单的数学运算而已，若需要读取文件数据，使用FileReader即可 🔥
         */
        const fileChunk = createChunks(file, 1 * 1024 * 1024)
        const res = await hash(fileChunk)
        console.log('文件hash' + res)
      }

      /*
       * 分片计算hash
       * @思路：
       *   1. 先读取第一个分块
       *   2. 然后递归调用自身，再读下一个分块
       * 
       * 计算hash比较耗时间，一般不会放在主线程进行，一般会单独开启一个线程来处理 （web worker）
       * 这样避免浏览器卡死
       * 
       * https://developer.mozilla.org/zh-CN/docs/Web/API/Web_Workers_API/Using_web_workers
       * https://juejin.cn/post/7139718200177983524
       * 
       * 放到单独线程处理，可能还会发生卡顿，因为它是一个CPU密集的任务，解决方案：
       *  1.先粗略把文件分为几个大块，单独计算每个大块的hash
       *  2.然后再对大块分小块，进行文件上传
       */
      function hash(chunks) {
        const spark = new SparkMD5()

        return new Promise((resolve, reject) => {
          function _read(i) {
            if (i >= chunks.length) {
              resolve(spark.end())
              return // 读取完成
            }
            // 获取分块数据
            const blob = chunks[i]
            const reader = new FileReader()

            // 分片数据读取完成
            reader.onload = e => {
              const bytes = e.target.result // 读取到的字符串
              // 把这个字节数组，使用增量hash计算
              spark.append(bytes)
              // 读取下一个分块
              _read(i + 1)
            }

            // 读取分块字节数
            reader.readAsArrayBuffer(blob)
          }
          _read(0) // 首先读取第一个分块
        })
      }

      // 创建分片
      function createChunks(file, chunkSize) {
        const result = []
        for (let i = 0; i < file.size; i += chunkSize) {
          result.push(file.slice(i, i + chunkSize))
        }
        return result
      }
    </script>
  </body>
</html>
